{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import NLTK for Tokenization, Stemming and Classifier\n",
    "\n",
    "Random module for random.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "# word stemmer\n",
    "stemmer = LancasterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we read data, clean it and store it in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input = open(\"clickbait_data\") #open file for read (clickbait)\n",
    "data = []\n",
    "next_line = file_input.readline() #getting data from file\n",
    "while(next_line):\n",
    "    if(next_line == '\\n'):\n",
    "        pass\n",
    "    else:\n",
    "        data.append((next_line.rstrip('\\n'),1))\n",
    "    next_line = file_input.readline()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input = open(\"non_clickbait_data\") #open file for read (non-clickbait)\n",
    "next_line = file_input.readline()\n",
    "while(next_line): #getting data from file\n",
    "    if(next_line == '\\n'):\n",
    "        pass\n",
    "    else:\n",
    "        data.append((next_line.rstrip('\\n'),0))\n",
    "    next_line = file_input.readline()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of word gets all the words that feature in the headlines\n",
    "\n",
    "I was getting some error due to non-unicode character. Thus, using try and exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "new_data = []\n",
    "for headline in data:\n",
    "    flag = 1\n",
    "    try:\n",
    "        for word in nltk.word_tokenize(headline[0]):\n",
    "            try:\n",
    "                stemmed_word = stemmer.stem(word.lower())\n",
    "                all_words.append(stemmed_word)\n",
    "            except:\n",
    "                flag = 0\n",
    "                break\n",
    "    except:\n",
    "        flag = 0\n",
    "    \n",
    "    finally:\n",
    "        if(flag == 1):\n",
    "            new_data.append(headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, get a frequency disturbution of the array.\n",
    "\n",
    "This gets all the unique words in the headlines, along with the number of times they have occured.\n",
    "\n",
    "We select the top 3000 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "word_features = list(all_words.keys())[:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code extract feature_map for each headline.\n",
    "\n",
    "For each headline, it checks whether the word_features occur in that headline or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = {}\n",
    "    for w in nltk.word_tokenize(document):\n",
    "        stemmed_word = stemmer.stem(w.lower())\n",
    "        words[stemmed_word] = 1\n",
    "    \n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(headline[0]), headline[1]) for headline in new_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set that we'll train our classifier with\n",
    "training_set = featuresets[:22000]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[22000:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classifier accuracy percent:', 81.28874885659113)\n",
      "Most Informative Features\n",
      "                    bomb = True                0 : 1      =    152.5 : 1.0\n",
      "                  beauty = True                1 : 0      =     95.6 : 1.0\n",
      "                    bush = True                0 : 1      =     53.1 : 1.0\n",
      "                  econom = True                0 : 1      =     50.4 : 1.0\n",
      "                      af = True                1 : 0      =     47.7 : 1.0\n",
      "                      uk = True                0 : 1      =     33.9 : 1.0\n",
      "                    russ = True                0 : 1      =     33.0 : 1.0\n",
      "                   dress = True                1 : 0      =     30.6 : 1.0\n",
      "                  remind = True                1 : 0      =     29.9 : 1.0\n",
      "                     her = True                1 : 0      =     29.9 : 1.0\n",
      "                    taiw = True                0 : 1      =     29.4 : 1.0\n",
      "                    unit = True                0 : 1      =     28.7 : 1.0\n",
      "                     vot = True                0 : 1      =     28.1 : 1.0\n",
      "                    best = True                1 : 0      =     27.4 : 1.0\n",
      "                   plant = True                0 : 1      =     27.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
